"""Async CLI orchestrator.

Builds the blocklist and whitelist in parallel from ``data/`` sources and
writes normalized outputs under ``output/`` with a final summary report.
"""

from __future__ import annotations

from asyncio import gather, to_thread
from datetime import datetime, timezone
from time import time
from types import SimpleNamespace
from typing import List, Tuple

from .constants import ADLIST_OUTPUT, ADLISTS, WHITELIST_OUTPUT, WHITELISTS
from .content import generate_list, separate_blocklist_whitelist
from .fetcher import fetch
from .io import load_sources, write_output
from .models import Source
from .redundancy import generate_redundancy_report
from .reporting import generate_report
from .status import GroupedStatusDisplay, StatusSpinner


def _generate_header(
    list_type: str,
    total_entries: int,
    domains: int,
    abp_rules: int,
    sources_count: int,
) -> str:
    """Create a formatted header for an output file.

    Args:
        list_type: "Adlist" or "Whitelist".
        total_entries: Count of all entries written.
        domains: Count of plain-domain entries.
        abp_rules: Count of ABP-style rules.
        sources_count: Number of sources processed.

    Returns:
        A multi-line comment string suitable to prepend to the file.
    """
    now = datetime.now(timezone.utc)
    timestamp = now.strftime("%Y-%m-%d %H:%M:%S UTC")

    header = f"""# {list_type} - Generated by Adlist-Parser
# https://github.com/Toomas633/Adlist-Parser
#
# Created/modified: {timestamp}
# Total entries: {total_entries:,}
# Domains: {domains:,}
# ABP-style rules: {abp_rules:,}
# Sources processed: {sources_count}
#
# This file is automatically generated. Do not edit manually.
# To update, run: adlist-parser or python -m adparser
#
"""
    return header


async def _fetch_with_progress(sources: List[Source], spinner: StatusSpinner):
    """Fetch sources and update the spinner with progress callbacks."""

    def progress_callback(completed: int, total: int):
        spinner.update_progress(completed, total)

    return await to_thread(fetch, sources, progress_callback)


async def _generate_adlist(spinner: StatusSpinner):
    """Build the adlist from ``ADLISTS`` and write ``ADLIST_OUTPUT``.

    Args:
        spinner: Status spinner used for live progress updates.
    """

    sources: List[Source]
    sources = await spinner.show_progress(
        "Adlist: Loading sources...", to_thread(load_sources, ADLISTS)
    )

    results: List[Tuple[Source, List[str]]]
    failed_sources: List[Source]
    results, failed_sources = await spinner.show_progress(
        "Adlist: Fetching content...", _fetch_with_progress(sources, spinner)
    )

    domains: List[str]
    abp_rules: List[str]
    failed_sources: List[Source]
    domains, abp_rules, failed_sources = await spinner.show_progress(
        "Adlist: Processing domains...",
        to_thread(generate_list, results, sources, failed_sources),
    )

    try:
        old_lines: List[str] = await spinner.show_progress(
            "Adlist: Loading previous output...",
            to_thread(_read_non_comment_lines, ADLIST_OUTPUT),
        )
    except FileNotFoundError:
        old_lines = []

    combined: List[str] = domains + abp_rules
    seen = set(combined)
    for line in old_lines:
        if line not in seen:
            combined.append(line)
            seen.add(line)
    header = _generate_header(
        "Adlist",
        len(combined),
        len(domains),
        len(abp_rules),
        len(sources),
    )
    await spinner.show_progress(
        "Adlist: Writing output...",
        to_thread(write_output, ADLIST_OUTPUT, combined, header),
    )
    msg = (
        f"âœ… Adlist: Complete - {len(combined)} entries "
        f"({len(domains)} domains, {len(abp_rules)} ABP rules)"
    )
    spinner.update_status(msg)

    return (
        len(sources),
        len(combined),
        len(domains),
        len(abp_rules),
        failed_sources,
        results,
        sources,
    )


async def _generate_whitelist(spinner: StatusSpinner):
    """Build the whitelist from ``WHITELISTS`` and write ``WHITELIST_OUTPUT``.

    Args:
        spinner: Status spinner used for live progress updates.
    """

    sources: List[Source]
    sources = await spinner.show_progress(
        "Whitelist: Loading sources...", to_thread(load_sources, WHITELISTS)
    )

    results: List[Tuple[Source, List[str]]]
    failed_sources: List[Source]
    results, failed_sources = await spinner.show_progress(
        "Whitelist: Fetching content...", _fetch_with_progress(sources, spinner)
    )

    domains: List[str]
    abp_rules: List[str]
    failed_sources: List[Source]
    domains, abp_rules, failed_sources = await spinner.show_progress(
        "Whitelist: Processing domains...",
        to_thread(generate_list, results, sources, failed_sources),
    )

    combined = domains + abp_rules
    header = _generate_header(
        "Whitelist",
        len(combined),
        len(domains),
        len(abp_rules),
        len(sources),
    )
    await spinner.show_progress(
        "Whitelist: Writing output...",
        to_thread(write_output, WHITELIST_OUTPUT, combined, header),
    )
    msg = (
        f"âœ… Whitelist: Complete - {len(combined)} entries "
        f"({len(domains)} domains, {len(abp_rules)} ABP rules)"
    )
    spinner.update_status(msg)

    return (
        len(sources),
        len(combined),
        len(domains),
        len(abp_rules),
        failed_sources,
        results,
        sources,
    )


async def main() -> int:
    """Run both pipelines concurrently and print a summary.

    Returns:
        Process exit code (0 on success).
    """
    start_time = time()

    print("ðŸš€ Starting Adlist-Parser...")
    print("âš¡ Processing adlists and whitelists concurrently...")

    status_display = GroupedStatusDisplay(initial_lines_offset=2)

    sp = SimpleNamespace(
        whitelist_redundancy=status_display.allocate_line(),
        adlist_redundancy=status_display.allocate_line(),
        postproc=status_display.allocate_line(),
        whitelist=status_display.allocate_line(),
        adlist=status_display.allocate_line(),
    )

    ad_res, wl_res = await gather(
        _generate_adlist(sp.adlist), _generate_whitelist(sp.whitelist)
    )

    pp = await sp.postproc.show_progress(
        "Post-processing: Separating blocklist and whitelist entries...",
        _run_post_processing(ad_res[0], wl_res[0]),
    )

    sp.postproc.update_status(
        f"âœ… Post-processing complete: Adlist {pp[0]:,} | Whitelist {pp[3]:,}"
    )

    adl_red, wht_red = await gather(
        generate_redundancy_report(
            ad_res[5],
            ad_res[4],
            ad_res[6],
            sp.adlist_redundancy,
            "Adlist",
        ),
        generate_redundancy_report(
            wl_res[5],
            wl_res[4],
            wl_res[6],
            sp.whitelist_redundancy,
            "Whitelist",
        ),
    )

    status_display.finalize()

    generate_report(
        (
            ad_res[0],
            pp[0],
            pp[1],
            pp[2],
            ad_res[4],
            adl_red,
        ),
        (
            wl_res[0],
            pp[3],
            pp[4],
            pp[5],
            wl_res[4],
            wht_red,
        ),
        start_time,
    )

    return 0


async def _run_post_processing(
    adlist_sources: int, whitelist_sources: int
) -> Tuple[int, int, int, int, int, int]:
    """Post-process outputs to separate blocklist/whitelist and rewrite headers.

    Reads the freshly written adlist and whitelist, separates entries so that
    allowlist items move to the whitelist and shadowed items are dropped, then
    rewrites both files with updated headers and counts.

    Args:
        adlist_sources: Number of adlist sources processed.
        whitelist_sources: Number of whitelist sources processed.

    Returns:
        Tuple of counts in the order:
        (adlist_total, adlist_domains, adlist_abp, whitelist_total,
         whitelist_domains, whitelist_abp).
    """
    adlist_lines = await to_thread(_read_non_comment_lines, ADLIST_OUTPUT)
    whitelist_lines = await to_thread(_read_non_comment_lines, WHITELIST_OUTPUT)

    cleaned_adlist, cleaned_whitelist = await to_thread(
        separate_blocklist_whitelist, adlist_lines, whitelist_lines
    )

    adlist_plain = [e for e in cleaned_adlist if not e.startswith('||')]
    adlist_abp_rules = [e for e in cleaned_adlist if e.startswith('||')]
    whitelist_plain = [e for e in cleaned_whitelist if not e.startswith('@@||')]
    whitelist_abp_rules = [e for e in cleaned_whitelist if e.startswith('@@||')]

    adlist_header = _generate_header(
        "Adlist",
        len(cleaned_adlist),
        len(adlist_plain),
        len(adlist_abp_rules),
        adlist_sources,
    )

    whitelist_header = _generate_header(
        "Whitelist",
        len(cleaned_whitelist),
        len(whitelist_plain),
        len(whitelist_abp_rules),
        whitelist_sources,
    )

    await to_thread(_write_with_header, ADLIST_OUTPUT, adlist_header, cleaned_adlist)
    await to_thread(
        _write_with_header, WHITELIST_OUTPUT, whitelist_header, cleaned_whitelist
    )

    return (
        len(cleaned_adlist),
        len(adlist_plain),
        len(adlist_abp_rules),
        len(cleaned_whitelist),
        len(whitelist_plain),
        len(whitelist_abp_rules),
    )


def _read_non_comment_lines(path: str) -> list[str]:
    """Return non-empty, non-comment lines from a file (stripped)."""
    with open(path, 'r', encoding='utf-8') as f:
        return [line.strip() for line in f if line.strip() and not line.startswith('#')]


def _write_with_header(path: str, header: str, lines: list[str]) -> None:
    """Write a header and lines to disk using LF line endings."""
    with open(path, 'w', encoding='utf-8', newline='\n') as f:
        f.write(header)
        f.write('\n'.join(lines))
        if lines:
            f.write('\n')
